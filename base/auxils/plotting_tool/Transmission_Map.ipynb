{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Set Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set options here.\n",
    "#Structural options\n",
    "filetype_input = 'csv' #Choose input file type: 'gdx' or 'csv' \n",
    "gams_dir = 'C:\\GAMS\\36' #Only required if filetype_input == 'gdx'\n",
    "market = 'DayAhead' #Choose from ['Balancing', 'DayAhead', 'FullYear', 'Investment']\n",
    "COMMODITY = 'Electricity' #Choose from: ['Electricity', 'H2', 'Other']. Add to csv-files name (only relevant if filetype_input == 'csv'). If 'Other': go to cell 1.4.0.\n",
    "SCENARIO = 'hubs' #Add scenario to read file name\n",
    "YEAR = 'all' #Add year to read file name (e.g. '2025', '2035', 'full')\n",
    "SUBSET = 'all' #Add subset to read file name (e.g. 'full')\n",
    "year = 2035 #Year to be displayed\n",
    "LINES = 'Capacity' #Choose from: ['Capacity', 'Flow', 'CongestionFlow']. For 'CongestionFlow', exo_end automatically switches to 'Total'.\n",
    "exo_end = 'Total' # Choose from ['Endogenous', 'Exogenous', 'Total']. For 'CongestionFlow', exo_end automatically switches to 'Total'.\n",
    "S = 'S02' #Season \n",
    "T = 'T073' #Hour\n",
    "\n",
    "# hubs\n",
    "hub_display = True\n",
    "hub_size = 10\n",
    "hub_decimals = 0 #Number of decimals shown for hub capacities\n",
    "background_hubsize = True #Displaying the true size of the hub as a circle on the map.\n",
    "hub_area = 2.8 #MW / km^2, background hub size on map. \n",
    "hub_area_opacity = 0.3 #Opacity of background hub size. \n",
    "\n",
    "#Visual options\n",
    "label_min = 4 #Minimum transmission capacity (GW) shown on map in text\n",
    "font_line = 10 #Font size of transmission line labels\n",
    "font_hub = 10 #Font size of hub labels\n",
    "font_region = 12 #Font size of region labels\n",
    "line_decimals = 1 #Number of decimals shown for line capacities\n",
    "line_width_constant = 5 #Constant related to thickness of lines: the higher the number, the narrower the lines will be\n",
    "flowline_breaks = [0, 40, 94.999, 100] #Breaks for different congestion categories\n",
    "legend_values = ['Fully congested', '40-95% congested', '< 50% congested'] #Values displayed in legend\n",
    "\n",
    "#colors\n",
    "background_color = 'white'\n",
    "regions_ext_color = 'lightgrey'\n",
    "regions_model_color = 'grey'\n",
    "region_text = 'black'\n",
    "capline_color = 'orange'\n",
    "flowline_color = ['#3D9200', '#feb24c','#960028']\n",
    "line_text = 'black'\n",
    "hub_color = 'lightblue'\n",
    "hub_background_color = 'lightblue'\n",
    "hub_text = 'black'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import gdxpds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from IPython.display import HTML, display\n",
    "import json\n",
    "from folium.features import DivIcon #For text labels on hubs\n",
    "from IPython.display import display, HTML\n",
    "from csv import reader\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read geographic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path('.\\input')\n",
    "\n",
    "#Load coordinates files \n",
    "df_unique = pd.read_csv(project_dir/'geo_files/coordinates_RRR.csv')\n",
    "df_region = df_unique.loc[df_unique['Type'] == 'region', ]\n",
    "df_bypass = pd.read_csv(project_dir/'geo_files/bypass_lines.csv') # coordinates of 'hooks' in indirect lines, to avoid going trespassing third regions\n",
    "\n",
    "\n",
    "#Define names of geojson and shapefile layers\n",
    "r_in = list(df_unique.loc[(df_unique['Display'] == 1) & (df_unique['Type'] == 'region'), 'RRR'])\n",
    "r_out = list(df_unique.loc[(df_unique['Display'] == 0) & (df_unique['Type'] == 'region'), 'RRR'])\n",
    "\n",
    "layers_in = {region: '' for region in r_in}\n",
    "layers_out = {region: '' for region in r_out}\n",
    "\n",
    "#Create dictionaries with layer names for each region; if both a shapefile and geojson file are available for one region, the geojson file is used. \n",
    "for region in r_in:\n",
    "    layers_in[region] = glob.glob(f'{project_dir}/geo_files/geojson_files/'+ region + '.geojson')\n",
    "    if bool(layers_in[region]) == False:\n",
    "        layers_in[region] = glob.glob(f'{project_dir}/geo_files/shapefiles/'+ region + '.shp')\n",
    "for region in r_out:\n",
    "    layers_out[region] = glob.glob(f'{project_dir}/geo_files/geojson_files/'+ region + '.geojson')\n",
    "    if bool(layers_out[region]) == False:\n",
    "        layers_out[region] = glob.glob(f'{project_dir}/geo_files/shapefiles/'+ region + '.shp')\n",
    "\n",
    "for region in layers_in:\n",
    "    layers_in[region] = str(layers_in[region])[2:-2] #Remove brackets from file names\n",
    "for region in layers_out:\n",
    "    layers_out[region] = str(layers_out[region])[2:-2] #Remove brackets from file names\n",
    "\n",
    "    \n",
    "#Convert shapefiles to geojson files  \n",
    "for region in layers_out:\n",
    "    if layers_out[region][-4:] == '.shp':\n",
    "        gpd.read_file(layers_out[region]).to_file(f'{project_dir}/geo_files/geojson_files/'+ region + '.geojson', driver='GeoJSON')\n",
    "        layers_out[region] = layers_out[region].replace('shapefiles', 'geojson_files').replace('.shp', '.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Read run-specific files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.0 If COMMODITY == 'Other': define variables or file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMODITY == 'Other':\n",
    "    if filetype_input == 'gdx':\n",
    "        var_list = ['G_CAP_YCRAF', 'XH2_CAP_YCR', 'XH2_FLOW_YCRST', 'PRO_YCRAGFST'] #Fill in variables to read, e.g. ['G_CAP_YCRAF', 'X{COMMODITY}_CAP_YCR', 'X{COMMODITY}_FLOW_YCRST', 'PRO_YCRAGST']\n",
    "    if filetype_input == 'csv':\n",
    "        flow_file = 'FlowH2Hourly_'+ SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv' #Fill in flow file name if applicable, e.g. 'Flow{COMMODITY}Hourly_'+ SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv'\n",
    "        transcap_file = 'CapacityH2Transmission_' + SCENARIO + '_' + YEAR + '_'+ SUBSET + '.csv' #Fill in transmission capacity file name, e.g. 'Capacity{COMMODITY}Transmission_'+ SCENARIO + '_' + YEAR + '_'+ SUBSET + '.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4A - GDX Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4A.1 Function: reading gdx-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filetype_input == 'gdx':\n",
    "    def df_creation(gdx_file, varname):\n",
    "        df = pd.DataFrame()\n",
    "        if '_' in gdx_file:\n",
    "                # if yes: extract scenario name from gdx filename\n",
    "            scenario = gdx_file.split('_', 3)[-3]\n",
    "            year = gdx_file.split('_', 3)[-2]\n",
    "            subset = gdx_file.split('_', 3)[-1][:-4]\n",
    "            market = gdx_file.split('\\\\', 1)[0].split('/',3)[-1]\n",
    "        else:\n",
    "               # if no: use nan instead\n",
    "            scenario = 'nan'\n",
    "\n",
    "        # create empty temporary dataframe and load the gdx data into it\n",
    "        temp = pd.DataFrame()\n",
    "        temp = gdxpds.to_dataframe(gdx_file, varname, gams_dir=gams_dir,\n",
    "                               old_interface=False)\n",
    "\n",
    "        # add a scenario column with the scenario name of the current iteration\n",
    "        temp['Scenario'] = scenario\n",
    "        temp['Market']  = market\n",
    "        temp['run'] = scenario + '_' + year + '_' + subset\n",
    "\n",
    "        # rearrange the columns' order\n",
    "        cols = list(temp.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        temp = temp[cols]\n",
    "\n",
    "        # concatenate the temporary dataframe to the preceeding data\n",
    "        df = pd.concat([df, temp], sort=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4A.2 - Define var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filetype_input == 'gdx':\n",
    "    if COMMODITY == 'Electricity':\n",
    "        var_list = []\n",
    "        if LINES == 'Capacity' or LINES == 'CongestionFlow': \n",
    "            var_list = var_list + ['G_CAP_YCRAF', 'X_CAP_YCR']\n",
    "        if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "            var_list = var_list + ['X_FLOW_YCRST']\n",
    "        if hub_display == True:\n",
    "            var_list = var_list + ['PRO_YCRAGFST']\n",
    "    if COMMODITY == 'H2':\n",
    "        var_list = []\n",
    "        if LINES == 'Capacity' or LINES == 'CongestionFlow': \n",
    "            var_list = var_list + ['G_CAP_YCRAF', 'XH2_CAP_YCR']\n",
    "        if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "            var_list = var_list + ['XH2_FLOW_YCRST']\n",
    "        if hub_display == True:\n",
    "            var_list = var_list + ['PRO_YCRAGFST']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4A.3 - Use function to read inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filetype_input == 'gdx':\n",
    "    runs = list()\n",
    "    gdx_file_list = list()\n",
    "\n",
    "    # directory to the input gdx file(s)\n",
    "    #gdx_file_list = gdx_file_list + glob.glob('./input/results/'+ market + '/*.gdx')\n",
    "    \n",
    "    gdx_file =  glob.glob('./input/results/'+ market + '\\\\MainResults_' + SCENARIO + '_'  + YEAR + '_' + SUBSET + '.gdx')\n",
    "    gdx_file = gdx_file[0]\n",
    "\n",
    "    all_df = {varname: df for varname, df in zip(var_list,var_list)}\n",
    "\n",
    "\n",
    "    for varname, df in zip(var_list, var_list):\n",
    "        all_df[varname] = df_creation(gdx_file, varname)\n",
    "        if all_df[varname]['run'][0] not in runs:\n",
    "            runs.append(all_df[varname]['run'][0])\n",
    "\n",
    "    #run_dict = dict(zip(gdx_file_list, runs) )\n",
    "    #all_df = dict((run_dict[key], value) for (key, value) in all_df.items())\n",
    "    \n",
    "    #Transmission capacity data\n",
    "    if LINES == 'Capacity' or LINES == 'CongestionFlow':\n",
    "        if COMMODITY == 'Electricity':\n",
    "            df_capacity = all_df['X_CAP_YCR']\n",
    "        if COMMODITY == 'H2':\n",
    "            df_capacity = all_df['XH2_CAP_YCR']\n",
    "        if COMMODITY == 'Other':\n",
    "            df_capacity = all_df[var_list[1]]\n",
    "\n",
    "    #Transmission flow data\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow': \n",
    "        if COMMODITY == 'Electricity':\n",
    "            df_flow = all_df['X_FLOW_YCRST']\n",
    "        if COMMODITY == 'H2':\n",
    "            df_flow = all_df['XH2_FLOW_YCRST']\n",
    "    if COMMODITY == 'Other':\n",
    "        if LINES == 'Flow':\n",
    "            df_flow = all_df[var_list[1]]\n",
    "        if LINES == 'CongestionFlow':\n",
    "            df_flow = all_df[var_list[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4A.4 - Hub data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filetype_input == 'gdx' and hub_display == True:\n",
    "    hub_windgen = (pd.read_csv(project_dir/'geo_files/hub_technologies.csv', sep = ',', quotechar = '\"').hub_name) \n",
    "    df_capgen = all_df['G_CAP_YCRAF']\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        df_hubprod = all_df['PRO_YCRAGFST']\n",
    "        df_hubprod['Y'] = df_hubprod['Y'].astype(int)\n",
    "        df_hubprod = df_hubprod.loc[(df_hubprod['G'].isin(hub_windgen)) & (df_hubprod['TECH_TYPE'] == 'WIND-OFF') & \\\n",
    "                                    (df_hubprod['Y']==year) & (df_hubprod['SSS'] == S) & (df_hubprod['TTT']==T), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4B1 - Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name = 'Transmission' + COMMODITY + '_' + LINES + '_' + str(year) + '_Map.html'\n",
    "if filetype_input == 'csv':\n",
    "    generation_file = 'CapacityGeneration_'+  SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv'\n",
    "    if COMMODITY == 'Electricity':\n",
    "        flow_file = 'FlowElectricityHourly_'+ SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv'\n",
    "        transcap_file = 'CapacityElectricityTransmission_'+ SCENARIO + '_' + YEAR + '_'+ SUBSET + '.csv'\n",
    "    if COMMODITY == 'H2':\n",
    "        flow_file = 'FlowH2Hourly_'+ SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv'\n",
    "        transcap_file = 'CapacityH2Transmission_'+ SCENARIO + '_' + YEAR + '_'+ SUBSET + '.csv'\n",
    "     \n",
    "    #Transmission capacity data\n",
    "    df_capacity = pd.read_csv(str(project_dir) + '/results/' + str(market) + '/' + str(transcap_file), sep = ',', quotechar = '\"') \n",
    "    #Transmission flow data\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        df_flow = pd.read_csv(str(project_dir) + '/results/' + str(market) + '/' + str(flow_file), sep = ',', quotechar = '\"')\n",
    "\n",
    "    if hub_display == True:\n",
    "        prod_file = 'ProductionHourly_'+ SCENARIO + '_' + YEAR + '_' + SUBSET + '.csv'\n",
    "        hub_windgen = (pd.read_csv(project_dir/'geo_files/hub_technologies.csv', sep = ',', quotechar = '\"').hub_name) \n",
    "        #Generation capacity data\n",
    "        df_capgen = pd.read_csv(str(project_dir) + '/results/' + str(market) + '/' + str(generation_file), sep = ',', quotechar = '\"') \n",
    "        if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        #Hub production data\n",
    "            df_hubprod = pd.read_csv(str(project_dir) + '/results/' + str(market) + '/' + str(prod_file), sep = ',', quotechar = '\"') \n",
    "            df_hubprod = df_hubprod.loc[(df_hubprod['G'].isin(hub_windgen)) & (df_hubprod['TECH_TYPE'] == 'WIND-OFF') & \\\n",
    "                                        (df_hubprod['Y']==year) & (df_hubprod['SSS'] == S) & (df_hubprod['TTT']==T), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4B2 - Calibrate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict = {'Val':'Value', 'Y':'Year', 'C':'Country'}\n",
    "if LINES == 'Capacity' or LINES == 'CongestionFlow':\n",
    "    df_capacity = df_capacity.rename(columns = column_dict)\n",
    "if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "    df_flow = df_flow.rename(columns = column_dict)\n",
    "if hub_display == True:\n",
    "    df_capgen = df_capgen.rename(columns = column_dict)\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow': \n",
    "            df_hubprod = df_hubprod.rename(columns = column_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Processing of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Replace \"EPS\" with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace possible \"Eps\" with 0\n",
    "df_capacity.Value=df_capacity.Value.replace('Eps', 0)\n",
    "df_capacity.Value=pd.to_numeric(df_capacity.Value)\n",
    "if LINES == 'Flow' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Capacity'\n",
    "    df_flow.Value=df_flow.Value.replace('Eps', 0)\n",
    "    df_flow.Value=pd.to_numeric(df_flow.Value)\n",
    "if hub_display == True:\n",
    "    df_capgen.Value=df_capgen.Value.replace('Eps', 0)\n",
    "    df_capgen.Value=pd.to_numeric(df_capgen.Value)\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        df_hubprod.Value=df_hubprod.Value.replace('Eps', 0)\n",
    "        df_hubprod.Value=pd.to_numeric(df_hubprod.Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Add Coordinates + Select Time + Convert Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flows\n",
    "if LINES == 'Flow' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Capacity'\n",
    "    df_flow['Year'] = df_flow['Year'].astype(int)\n",
    "    #Keep only data from moment of interest\n",
    "    df_flow = df_flow.loc[df_flow['Year'] == year] \n",
    "    df_flow = df_flow.loc[df_flow['SSS'] == S,]\n",
    "    df_flow = df_flow.loc[df_flow['TTT'] == T, ]\n",
    "    for i,row in df_flow.iterrows():\n",
    "        for j in range(0,len(df_unique)):\n",
    "            if df_flow.loc[i,'IRRRE'] == df_unique.loc[j, 'RRR']:\n",
    "                df_flow.loc[i,'LatExp'] = df_unique.loc[j, 'Lat']\n",
    "                df_flow.loc[i,'LonExp'] = df_unique.loc[j, 'Lon']\n",
    "            if df_flow.loc[i,'IRRRI'] == df_unique.loc[j, 'RRR']:\n",
    "                df_flow.loc[i,'LatImp'] = df_unique.loc[j, 'Lat']\n",
    "                df_flow.loc[i,'LonImp'] = df_unique.loc[j, 'Lon']\n",
    "\n",
    "    #Convert flow from MWh to GWh\n",
    "    df_flow['Value'] = df_flow['Value'] / 1000\n",
    "    df_flow = df_flow.reset_index(drop = True)\n",
    "    if len(df_flow) == 0:\n",
    "        print(\"Error: Timestep not in data; check year, S and T.\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Group hub data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation Capacities\n",
    "if hub_display == True:\n",
    "    df_capgen['Year'] = df_capgen['Year'].astype(int)\n",
    "    df_capgen = df_capgen.merge(df_unique, on = 'RRR', how = 'left', left_index = True).reset_index(drop = True) #Add coordinates of each region\n",
    "    df_capgen = df_capgen.loc[df_capgen['Year'] == year] #Keep only data from year of interest\n",
    "    df_hubcap = df_capgen.loc[df_capgen['G'].isin(hub_windgen),] #Keep only hub data \n",
    "    df_hubcap_agg = pd.DataFrame(df_hubcap.groupby(['Year', 'Country', 'RRR', 'Lat', 'Lon'])['Value'].sum().reset_index()) #Sum all capacities (of different wind turbines) at each location\n",
    "    df_hubcap_agg['Radius'] = np.sqrt(df_hubcap_agg['Value'] * 1000 / hub_area / np.pi) # Create column of hub radius (in kilometres)\n",
    "\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        #Merge all relevant hub info into one dataframe\n",
    "        df_hubprod = pd.DataFrame(df_hubprod.groupby(['Year', 'Country', 'RRR'])['Value'].sum().reset_index()) #Sum all production (of different wind turbines) at each location\n",
    "        df_hubprod.Value = df_hubprod.Value/1000\n",
    "        df_hubprod.rename(columns = {'Value': 'prod_GWh'}, inplace = True)\n",
    "        df_hub = pd.merge(df_hubcap_agg, df_hubprod[['RRR', 'prod_GWh']], on = 'RRR', how = 'left', left_index = True).reset_index(drop = True) \n",
    "        #Display a zero instead of NaN values (i.e. if there is no production in that hour, so df_hubprod row does not exist)\n",
    "        df_hub.loc[df_hub.prod_GWh.isna() == True, 'prod_GWh'] = 0\n",
    "    else: \n",
    "        df_hub = df_hubcap_agg.copy()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Prepare capacity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transmission Capacities\n",
    "if LINES == 'Capacity' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Flow'\n",
    "    df_capacity['Year'] = df_capacity['Year'].astype(int)\n",
    "    df_capacity = df_capacity.loc[df_capacity['Year'] == year, ].reset_index(drop = True) #Keep only data from year of interest\n",
    "    if exo_end == 'Total' or LINES == 'CongestionFlow':\n",
    "        col_keep = list(np.delete(np.array(df_capacity.columns),np.where((df_capacity.columns == 'VARIABLE_CATEGORY') | \\\n",
    "                                    (df_capacity.columns == 'Value')) )) #Create list with all columns except 'Variable_Category' and 'Value'\n",
    "        df_capacity = pd.DataFrame(df_capacity.groupby(col_keep)['Value'].sum().reset_index() )#Sum exogenous and endogenous capacity for each region\n",
    "    if exo_end == 'Endogenous' and LINES != 'CongestionFlow':\n",
    "        df_capacity = df_capacity.loc[df_capacity['VARIABLE_CATEGORY'] == 'ENDOGENOUS', ]\n",
    "    if exo_end == 'Exogenous' and LINES != 'CongestionFlow':\n",
    "        df_capacity = df_capacity.loc[df_capacity['VARIABLE_CATEGORY'] == 'EXOGENOUS', ]\n",
    "\n",
    "    for i,row in df_capacity.iterrows():\n",
    "        for j in range(0,len(df_unique)):\n",
    "            if df_capacity.loc[i,'IRRRE'] == df_unique.loc[j, 'RRR']:\n",
    "                df_capacity.loc[i,'LatExp'] = df_unique.loc[j, 'Lat']\n",
    "                df_capacity.loc[i,'LonExp'] = df_unique.loc[j, 'Lon']\n",
    "            if df_capacity.loc[i,'IRRRI'] == df_unique.loc[j, 'RRR']:\n",
    "                df_capacity.loc[i,'LatImp'] = df_unique.loc[j, 'Lat']\n",
    "                df_capacity.loc[i,'LonImp'] = df_unique.loc[j, 'Lon']\n",
    "    if len(df_capacity) == 0:\n",
    "        print(\"Error: No capacity found. Check year and exo_end.\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Add bypass coordinates for indirect lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LINES == 'Capacity':\n",
    "    df_bypass = pd.merge(df_bypass, df_capacity[['Year', 'Country', 'IRRRE', 'IRRRI', 'UNITS', 'Value']], on = ['IRRRE', 'IRRRI'], how = 'left')\n",
    "    #Replace existing row by 2 bypass rows\n",
    "    keys = list(df_bypass.columns.values)[0:2]\n",
    "    i1 = df_capacity.set_index(keys).index\n",
    "    i2 = df_bypass.set_index(keys).index\n",
    "    df_capacity = df_capacity[~i1.isin(i2)] #Delete existing rows that need bypass\n",
    "    df_capacity = df_capacity.append(df_bypass, ignore_index = True, sort = True) #Append bypass rows\n",
    "    \n",
    "if LINES == 'Flow' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Capacity'\n",
    "    df_bypass = pd.merge(df_bypass, df_flow[['Year', 'Country', 'IRRRE', 'IRRRI', 'SSS', 'TTT', 'UNITS', 'Value']], on = ['IRRRE', 'IRRRI'], how = 'left').dropna()\n",
    "    #Replace existing row by 2 bypass rows\n",
    "    keys = list(df_bypass.columns.values)[0:2]\n",
    "    i1 = df_flow.set_index(keys).index\n",
    "    i2 = df_bypass.set_index(keys).index\n",
    "    df_flow = df_flow[~i1.isin(i2)]#Delete existing rows that need bypass\n",
    "    df_flow = df_flow.append(df_bypass, ignore_index = True, sort = True)#Append bypass rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Calculate Congestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LINES == 'CongestionFlow': #Skip this cell in case LINES != 'CongestionFlow'\n",
    "    df_flow = pd.merge(df_flow, df_capacity[['Year', 'Country', 'IRRRE', 'IRRRI', 'Value']], on = ['Year', 'Country', 'IRRRE', 'IRRRI'], how = 'left')\n",
    "    df_flow.rename(columns={'Value_x': 'Value', 'Value_y' : 'Capacity'}, inplace = True)\n",
    "    df_flow['Congestion'] = df_flow['Value'] / df_flow['Capacity'] * 100\n",
    "\n",
    "    #Create color codes for congestion of lines\n",
    "    df_flow['color'] = pd.cut(df_flow['Congestion'], bins = flowline_breaks, labels = flowline_color )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 One direction capacity  lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When capacity is not the same in both directions, display one:\n",
    "for i,row in df_capacity.iterrows():\n",
    "    for k,row in df_capacity.iterrows():\n",
    "        if (df_capacity.loc[k,'IRRRE'] == df_capacity.loc[i,'IRRRI']) & (df_capacity.loc[k,'IRRRI'] == df_capacity.loc[i,'IRRRE']) & (df_capacity.loc[k,'Value'] != df_capacity.loc[i,'Value']):\n",
    "            df_capacity.loc[i,'Value'] = df_capacity.loc[k,'Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.8 Define line centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define centre of each transmission line\n",
    "if LINES == 'Flow' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Capacity'\n",
    "    df_flow['LatMid'] = (df_flow['LatImp'] + df_flow['LatExp']) /2\n",
    "    df_flow['LonMid'] = (df_flow['LonImp'] + df_flow['LonExp']) /2\n",
    "if LINES == 'Capacity' or LINES == 'CongestionFlow': #Skip this cell in case LINES == 'Flow'\n",
    "    df_capacity['LatMid'] = (df_capacity['LatImp'] + df_capacity['LatExp']) /2\n",
    "    df_capacity['LonMid'] = (df_capacity['LonImp'] + df_capacity['LonExp']) /2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create Map Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create map \n",
    "map_center = [55.220228, 10.419778]\n",
    "m = folium.Map(location= map_center, zoom_start=5, tiles='')\n",
    "#Add background layers (sea, regions in model, countries outside of model)\n",
    "folium.Polygon(locations = [[-90,-180], [90,-180], [90,180], [-90,180]], color = background_color, fill_color = background_color, opacity = 1, fill_opacity = 1 ).add_to(m) #Background\n",
    "\n",
    "for region in layers_in: \n",
    "    folium.GeoJson(data = layers_in[region], name = 'regions_in', \\\n",
    "               style_function = lambda x:{'fillColor': regions_model_color, 'fillOpacity': 0.5, 'color': regions_model_color, 'weight':1}).add_to(m) #Regions within model\n",
    "for region in layers_out: \n",
    "    folium.GeoJson(data = layers_out[region], name = 'regions_out', \\\n",
    "                   style_function = lambda x:{'fillColor': regions_ext_color, 'fillOpacity': 0.5, 'color': regions_ext_color, 'weight':1}).add_to(m) #Neighbouring countries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create background hub size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hub_display == True:\n",
    "    if background_hubsize == True:\n",
    "        for i,row in df_hub.iterrows():\n",
    "                folium.Circle(\n",
    "                  location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "                  popup=df_hub.loc[i,'RRR'],\n",
    "                  radius = df_hub.loc[i,'Radius']*1000,\n",
    "                  color = hub_background_color,\n",
    "                  opacity = 0,\n",
    "                  fill=True,\n",
    "                  fill_color = hub_background_color,\n",
    "                  fill_opacity = hub_area_opacity\n",
    "               ).add_to(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Add lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add capacity lines\n",
    "if LINES == 'Capacity':\n",
    "    for i,row in df_capacity.iterrows():\n",
    "        folium.PolyLine(([df_capacity.loc[i,'LatExp'], df_capacity.loc[i,'LonExp']], \\\n",
    "                             [df_capacity.loc[i,'LatImp'],df_capacity.loc[i,'LonImp']]), \\\n",
    "                            color=capline_color, line_cap = 'butt', weight=df_capacity.loc[i,'Value']/line_width_constant, opacity=1).add_to(m)  \n",
    "        if df_capacity.loc[i,'Value'] > label_min:\n",
    "            if line_decimals == 0:\n",
    "                folium.Marker(location=[df_capacity.loc[i,'LatMid'], df_capacity.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                            df_capacity.loc[i,'Value'].round(line_decimals).astype(int)))).add_to(m)\n",
    "            else: \n",
    "                folium.Marker(location=[df_capacity.loc[i,'LatMid'], df_capacity.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                            round(df_capacity.loc[i,'Value'],line_decimals)))).add_to(m)\n",
    "#Add flows (single color)                \n",
    "if LINES == 'Flow':\n",
    "    attr = {'font-weight': 'bold', 'font-size': '24'}\n",
    "    for i,row in df_flow.iterrows():\n",
    "        flow = folium.PolyLine(([df_flow.loc[i,'LatExp'], df_flow.loc[i,'LonExp']], \\\n",
    "                             [df_flow.loc[i,'LatImp'],df_flow.loc[i,'LonImp']]), \\\n",
    "                            color=capline_color, line_cap = 'butt', weight=df_flow.loc[i,'Value']/line_width_constant, opacity=1).add_to(m)   \n",
    "        plugins.PolyLineTextPath(flow, '\\u2192', repeat=False ,center = True, offset=6, orientation = -90, \\\n",
    "                                 attributes=attr).add_to(m)  #Arrow\n",
    "        if df_flow.loc[i,'Value'] > label_min:\n",
    "            if line_decimals == 0:\n",
    "                folium.Marker(location=[df_flow.loc[i,'LatMid'], df_flow.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                            df_flow.loc[i,'Value'].round(line_decimals).astype(int)))).add_to(m)\n",
    "            else: \n",
    "                folium.Marker(location=[df_flow.loc[i,'LatMid'], df_flow.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                            round(df_flow.loc[i,'Value'],line_decimals)))).add_to(m)    \n",
    "#Add flows (color based on congestion)\n",
    "if LINES == 'CongestionFlow':\n",
    "    attr = {'font-weight': 'bold', 'font-size': '24'}\n",
    "    for i,row in df_flow.iterrows():\n",
    "        flow = folium.PolyLine(([df_flow.loc[i,'LatExp'], df_flow.loc[i,'LonExp']], \\\n",
    "                             [df_flow.loc[i,'LatImp'],df_flow.loc[i,'LonImp']]), \\\n",
    "                            color=df_flow.loc[i,'color'], line_cap = 'butt', weight=df_flow.loc[i,'Value']/line_width_constant, opacity=1).add_to(m)   \n",
    "        plugins.PolyLineTextPath(flow, '\\u2192', repeat=False ,center = True, offset=6, orientation = -90, \\\n",
    "                                 attributes=attr).add_to(m)  #Arrow\n",
    "        if df_flow.loc[i,'Value'] > label_min:\n",
    "            if line_decimals == 0:\n",
    "                folium.Marker(location=[df_flow.loc[i,'LatMid'], df_flow.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                            df_flow.loc[i,'Value'].round(line_decimals).astype(int)))).add_to(m)\n",
    "            else: \n",
    "                folium.Marker(location=[df_flow.loc[i,'LatMid'], df_flow.loc[i,'LonMid']],\n",
    "                          icon=DivIcon(\n",
    "                              icon_size=(150,36), \n",
    "                                       icon_anchor=(11,7),\n",
    "                     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_line, line_text, \\\n",
    "                                round(df_flow.loc[i,'Value'],line_decimals)))).add_to(m)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Add region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add region names\n",
    "for i,row in df_region.loc[df_region['Display']==1, ].iterrows():\n",
    "    folium.Marker(location=[df_region.loc[i,'Lat'], df_region.loc[i,'Lon']],\n",
    "                  icon=DivIcon(\n",
    "                      icon_size=(150,36), \n",
    "                               icon_anchor=(7,7),\n",
    "     html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_region, region_text, df_region.loc[i,'RRR']))).add_to(m)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Add hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add hub capacities as bubbles\n",
    "if hub_display == True:\n",
    "    if LINES == 'Capacity': \n",
    "        for i,row in df_hub.iterrows():\n",
    "            folium.CircleMarker(\n",
    "              location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "              popup=df_hub.loc[i,'RRR'],\n",
    "              radius = hub_size,\n",
    "              color= hub_color,\n",
    "              opacity = 0,\n",
    "              fill=True,\n",
    "              fill_color= hub_color,\n",
    "              fill_opacity = 1\n",
    "           ).add_to(m)\n",
    "\n",
    "            if hub_decimals == 0:\n",
    "                folium.Marker(location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "                              icon=DivIcon(\n",
    "                                  icon_size=(150,36), \n",
    "                                           icon_anchor=(7,9),\n",
    "                 html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_hub, hub_text, df_hub.loc[i,'Value'].round(hub_decimals).astype(int)))).add_to(m)\n",
    "            else:\n",
    "                folium.Marker(location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "                              icon=DivIcon(\n",
    "                                  icon_size=(150,36), \n",
    "                                           icon_anchor=(7,9),\n",
    "                 html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_hub, hub_text, round(df_hub.loc[i,'Value'], hub_decimals)))).add_to(m)    \n",
    "\n",
    "    if LINES == 'Flow' or LINES == 'CongestionFlow':\n",
    "        for i,row in df_hub.iterrows():\n",
    "            folium.CircleMarker(\n",
    "              location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "              popup=df_hub.loc[i,'RRR'],\n",
    "              radius = hub_size,\n",
    "              color= hub_color,\n",
    "              opacity = 0,\n",
    "              fill=True,\n",
    "              fill_color= hub_color,\n",
    "              fill_opacity = 1\n",
    "           ).add_to(m)\n",
    "\n",
    "            if hub_decimals == 0:\n",
    "                folium.Marker(location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "                              icon=DivIcon(\n",
    "                                  icon_size=(150,36), \n",
    "                                           icon_anchor=(7,9),\n",
    "                 html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_hub, hub_text, df_hub.loc[i,'prod_GWh'].round(hub_decimals).astype(int)))).add_to(m)\n",
    "            else:\n",
    "                folium.Marker(location=[df_hub.loc[i,'Lat'], df_hub.loc[i,'Lon']],\n",
    "                              icon=DivIcon(\n",
    "                                  icon_size=(150,36), \n",
    "                                           icon_anchor=(7,9),\n",
    "                 html='<div style=\"font-size: {}pt; color : {}\">{}</div>'.format(font_hub, hub_text, round(df_hub.loc[i,'prod_GWh'], hub_decimals)))).add_to(m)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Add Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_keys = ['color1', 'color2', 'color3']\n",
    "color_dict = dict(zip(color_keys, flowline_color))\n",
    "legend_keys = ['item1', 'item2', 'item3']\n",
    "legend_dict = dict(zip(legend_keys, legend_values))\n",
    "\n",
    "if LINES == 'CongestionFlow':\n",
    "    from branca.element import Template, MacroElement\n",
    "\n",
    "    template = \"\"\"\n",
    "    {% macro html(this, kwargs) %}\n",
    "\n",
    "    <!doctype html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "      <meta charset=\"utf-8\">\n",
    "      <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "      <title>jQuery UI Draggable - Default functionality</title>\n",
    "      <link rel=\"stylesheet\" href=\"//code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css\">\n",
    "\n",
    "      <script src=\"https://code.jquery.com/jquery-1.12.4.js\"></script>\n",
    "      <script src=\"https://code.jquery.com/ui/1.12.1/jquery-ui.js\"></script>\n",
    "\n",
    "      <script>\n",
    "      $( function() {\n",
    "        $( \"#maplegend\" ).draggable({\n",
    "                        start: function (event, ui) {\n",
    "                            $(this).css({\n",
    "                                right: \"auto\",\n",
    "                                top: \"auto\",\n",
    "                                bottom: \"auto\"\n",
    "                            });\n",
    "                        }\n",
    "                    });\n",
    "    });\n",
    "\n",
    "      </script>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "\n",
    "    <div id='maplegend' class='maplegend' \n",
    "        style='position: absolute; z-index:9999; border:2px solid grey; background-color:rgba(255, 255, 255, 1);\n",
    "         border-radius:6px; padding: 10px; font-size:14px; right: 20px; bottom: 20px;'>\n",
    "\n",
    "    <div class='legend-title'>Congestion rate</div>\n",
    "    <div class='legend-scale'>\n",
    "      <ul class='legend-labels'>\n",
    "        <li><span style='background:color3;opacity:1;'></span>item1</li>\n",
    "        <li><span style='background:color2;opacity:1;'></span> item2 </li>\n",
    "        <li><span style='background:color1;opacity:1;'></span> item3 </li>\n",
    "\n",
    "      </ul>\n",
    "    </div>\n",
    "    </div>\n",
    "\n",
    "    </body>\n",
    "    </html>\n",
    "\n",
    "    <style type='text/css'>\n",
    "      .maplegend .legend-title {\n",
    "        text-align: left;\n",
    "        margin-bottom: 5px;\n",
    "        font-weight: bold;\n",
    "        font-size: 90%;\n",
    "        }\n",
    "      .maplegend .legend-scale ul {\n",
    "        margin: 0;\n",
    "        margin-bottom: 5px;\n",
    "        padding: 0;\n",
    "        float: left;\n",
    "        list-style: none;\n",
    "        }\n",
    "      .maplegend .legend-scale ul li {\n",
    "        font-size: 80%;\n",
    "        list-style: none;\n",
    "        margin-left: 0;\n",
    "        line-height: 18px;\n",
    "        margin-bottom: 2px;\n",
    "        }\n",
    "      .maplegend ul.legend-labels li span {\n",
    "        display: block;\n",
    "        float: left;\n",
    "        height: 16px;\n",
    "        width: 30px;\n",
    "        margin-right: 5px;\n",
    "        margin-left: 0;\n",
    "        border: 1px solid #999;\n",
    "        }\n",
    "      .maplegend .legend-source {\n",
    "        font-size: 80%;\n",
    "        color: #777;\n",
    "        clear: both;\n",
    "        }\n",
    "      .maplegend a {\n",
    "        color: #777;\n",
    "        }\n",
    "    </style>\n",
    "    {% endmacro %}\"\"\"\n",
    "    for key in color_dict.keys():\n",
    "        template = template.replace(key, color_dict[key])\n",
    "    for key in legend_dict.keys():\n",
    "        template = template.replace(key, legend_dict[key])\n",
    "    \n",
    "    macro = MacroElement()\n",
    "    macro._template = Template(template)\n",
    "\n",
    "    m.get_root().add_child(macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Transmission_Map output folder\n",
    "if not os.path.isdir('output/Transmission_Map/' + LINES + '/' + SCENARIO + '/' + market):\n",
    "    os.makedirs('output/Transmission_Map/' + LINES + '/' + SCENARIO + '/' + market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output/Transmission_Map/' + LINES + '/' + SCENARIO + '/' + market\n",
    "m.save(output_dir + '/' +  map_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Display Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
